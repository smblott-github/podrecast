#!/usr/bin/env python

# In Debian, the module "requests" is available in "python-requests".
#

import os, sys
from urlparse import urlparse, urlunparse
from tempfile import mkstemp

try:
   from requests import get
except:
   sys.stderr.write("import error: python-requests not found\n")
   sys.exit(1)

try:
   from lxml import objectify
except:
   sys.stderr.write("import error: python-lxml not found\n")
   sys.exit(1)

url = 'http://192.168.3.3/cgi-bin/podcast/Podcasts/Cycling/Velo-Cast'
directory = '/home/blott/tmp/repodcast/repodcast'
catchup = True
catchup = False

def fetch_url(url):
   try:
      print "get:", url
      response = get(url)
      if response.status_code != 200:
         raise Exception()
      return response.content
   except (KeyboardInterrupt, SystemExit):
      raise
   except:
      raise Exception("failed to download: " + url)

def parse(text,url):
   try:
      return objectify.fromstring(text)
   except (KeyboardInterrupt, SystemExit):
      raise
   except Exception as error:
      raise Exception("failed to parse rss: " + url)

def fetch_feed(url):
   text = fetch_url(url)
   return parse(text,url)

def chdir(directory):
   try:
      exists = os.path.isdir(directory)
      if not exists:
         os.makedirs(directory)
      os.chdir(directory)
      return not exists
   except (KeyboardInterrupt, SystemExit):
      raise
   except OSError as error: 
      if error.errno == os.errno.EEXIST and os.path.isdir(directory):
         pass
      else:
         raise Exception("failed to create/change directory: " + directory)
   except:
      raise Exception("failed to create/change directory: " + directory)

def touch(fname, times=None):
   print "touch:", fname
   with file(fname, 'a'):
      os.utime(fname, times)

def catchup_file(fname):
   return "." + fname + ".catchup"

def done_file(fname):
   return "." + fname + ".done"

def download_file(fname):
   return fname + ".repodcast_download"

def http_download(url,fname):
   tmp = None
   try:
      print "download:", url
      fd, tmp = mkstemp(dir=".", prefix=fname, suffix=".repodget.tmp")
      req = get(url, stream=True)
      for data in req.iter_content(chunk_size=4096): 
         if data:
            os.write(fd,data)
      os.close(fd)
      os.rename(tmp,fname)
      print "done:", fname
   except:
      if tmp and os.path.exists(tmp):
         os.unlink(tmp)
      raise

def handle_enclosue(catchup,enclosure):
   attributes = enclosure.attrib
   if not "url" in attributes:
      sys.stderr.write("enclosure without url!\n")
      return
   #
   url = urlparse(attributes["url"])
   fname = os.path.basename(url.path)
   #
   try:
      #
      if os.path.exists(catchup_file(fname)):
         # print "caught up:", fname
         return
      #
      if os.path.exists(done_file(fname)):
         # print "already done:", fname
         return
      #
      if os.path.exists(download_file(fname)):
         # print "already downloaded:", fname
         return
      #
      if os.path.exists(fname):
         # print "already exists:", fname
         return
      #
      if catchup:
         touch(catchup_file(fname))
         return
      #
      # OK.  Download the file.
      http_download(urlunparse(url),download_file(fname))
      touch(done_file(fname))
      #
   except (KeyboardInterrupt, SystemExit):
      raise
   except:
      raise Exception("failed to download: " + url)

def download_feed(catchup,directory,url):
   errors = 0
   enclosures = None
   try:
      catchup = chdir(directory) or catchup
      feed = fetch_feed(url)
      enclosures = feed.findall('.//enclosure')
   except (KeyboardInterrupt, SystemExit):
      raise
   except Exception as error:
      sys.stderr.write("error: " + str(error) + "\n")
      return 1
   #
   for enclosure in feed.findall('.//enclosure'):
      try:
         handle_enclosue(catchup,enclosure)
      except (KeyboardInterrupt, SystemExit):
         raise
      except:
         sys.stderr.write("error: " + str(error) + "\n")
         errors += 1
   #
   return errors

if __name__ == "__main__":
   errors = 0
   errors += download_feed(catchup,directory,url)
   #
   if 0 < errors:
      sys.stderr.write("feed errors: " + str(errors) + "\n")
   sys.exit(0 if errors == 0 else 1)

